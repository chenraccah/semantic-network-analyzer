# Semantic Network Analyzer

A powerful tool for analyzing and visualizing semantic networks from text data. Compare word co-occurrence patterns between different groups (e.g., parents vs teachers, customers vs employees, etc.).

## ğŸ¯ Features

- **Upload & Process**: Upload Excel/CSV files containing text responses from different groups
- **Word Unification**: Automatic and manual word mapping (plurals, synonyms, variants)
- **Network Visualization**: Interactive force-directed and clustered layouts
- **Comparative Analysis**: Side-by-side comparison of word usage patterns between groups
- **Centrality Metrics**: Degree, betweenness, closeness, eigenvector centrality
- **Clustering**: Automatic semantic clustering with multiple algorithms
- **Filtering**: By perspective, cluster, score threshold, edge weight
- **Export**: CSV, Excel, and image exports

## ğŸ—ï¸ Architecture

```
semantic-network-analyzer/
â”œâ”€â”€ frontend/                 # React + TypeScript frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/       # React components
â”‚   â”‚   â”œâ”€â”€ hooks/            # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ types/            # TypeScript type definitions
â”‚   â”‚   â”œâ”€â”€ utils/            # Utility functions
â”‚   â”‚   â””â”€â”€ styles/           # CSS/styled-components
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”œâ”€â”€ backend/                  # Python FastAPI backend
â”‚   â”œâ”€â”€ api/                  # API endpoints
â”‚   â”œâ”€â”€ core/                 # Core analysis logic
â”‚   â”œâ”€â”€ utils/                # Utility functions
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ docs/                     # Documentation
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+
- Python 3.9+
- npm or yarn

### Backend Setup

```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
uvicorn main:app --reload
```

### Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

## ğŸ“Š How It Works

### 1. Data Upload
Upload Excel or CSV files containing text responses. Each file represents one group (e.g., "parents.xlsx", "teachers.xlsx").

### 2. Text Processing
- Tokenization and cleaning
- Stopword removal
- Word unification (plurals, synonyms)
- Custom word mappings

### 3. Network Construction
- Build co-occurrence networks for each group
- Calculate edge weights based on co-occurrence frequency
- Compute centrality metrics

### 4. Comparison Analysis
- Normalize scores within each group
- Calculate differences and emphasis
- Identify group-specific patterns

### 5. Visualization
- Interactive network graph
- Filterable data table
- Multiple layout options
- Export capabilities

## ğŸ”§ Configuration

### Word Mappings
Define custom word unifications in the UI or via config file:

```json
{
  "mappings": {
    "collaborate": "collaboration",
    "collaborating": "collaboration",
    "teachers": "teacher"
  },
  "deletions": ["etc", "also", "however"]
}
```

### Stopwords
Customize stopword lists per language or domain.

## ğŸ“ˆ Metrics Explained

| Metric | Description |
|--------|-------------|
| **Degree** | Number of connections a word has |
| **Strength** | Sum of edge weights |
| **Betweenness** | How often a word bridges other words |
| **Closeness** | Average distance to all other words |
| **Eigenvector** | Influence based on connected words' importance |

## ğŸ¨ Visualization Options

### Layouts
- **Force-Directed**: Physics-based organic layout
- **Clustered**: Grouped by semantic clusters

### Color Modes
- **Emphasis**: Red (Group A), Green (Group B), Orange (Balanced)
- **Cluster**: Distinct colors per cluster

### Filters
- Perspective filter (group-specific views)
- Score threshold
- Edge weight threshold
- Cluster selection
- Show/hide individual words

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ¤ Contributing

Contributions welcome! Please read CONTRIBUTING.md for guidelines.
